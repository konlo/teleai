import base64
import re
from typing import Any, Dict, List
from uuid import uuid4

import streamlit as st
import pandas as pd
from langchain_community.callbacks.streamlit import StreamlitCallbackHandler

from core.agent import (
    SimpleCollectCallback,
    StdOutCallbackHandler,
    build_agent,
)
from core.llm import load_llm
from core.prompt import build_react_prompt, build_sql_prompt
from core.sql_tools import build_sql_tools
from core.tools import build_tools
from ui.history import get_history
from ui.sidebar import render_sidebar
from ui.viz import render_visualizations
from utils.session import (
    dataframe_signature,
    ensure_session_state,
    load_preview_from_databricks_query,
)


st.set_page_config(
    page_title="Telemetry Chatbot Telly",
    page_icon="âœ¨",
    layout="wide",
)

st.markdown(
    """
    <style>
    :root {
        font-size: 16px;
    }

    html,
    body,
    [data-testid="stAppViewContainer"] {
        font-size: 16px;
    }

    .block-container {
        max-width: 900px;
        margin: 0 auto;
        width: 100%;
        padding-left: 1.5rem;
        padding-right: 1.5rem;
    }

    [data-testid="stChatInput"] {
        width: 100%;
        max-width: 1000px;
        margin: 0 auto;
        padding-left: 1.5rem;
        padding-right: 1.5rem;
    }

    [data-testid="stChatInput"] > div {
        width: 100%;
        min-height: 5rem;
    }

    [data-testid="stChatInputTextArea"] {
        min-height: 5rem;
    }

    @media (max-width: 1200px) {
        .block-container,
        [data-testid="stChatInput"] {
            padding-left: 1rem;
            padding-right: 1rem;
        }
    }
    </style>
    """,
    unsafe_allow_html=True,
)

st.title("âœ¨ Telemetry Chatbot Telly")
st.caption("ë‘ CSV ë¹„êµ + ì´ìƒì  ì¤‘ì‹¬ EDA(ì›í´ë¦­) + SSD Telemetry ìœ í‹¸")


def _get_dataframes():
    ensure_session_state()
    render_sidebar()
    df_a = st.session_state["df_A_data"]
    df_b = st.session_state["df_B_data"]

    sig_a = dataframe_signature(df_a, st.session_state.get("csv_path", ""))
    sig_a_prev = st.session_state.get("df_A_signature", "")
    dataset_changed = sig_a != sig_a_prev
    st.session_state["df_A_signature"] = sig_a

    sig_b = dataframe_signature(df_b, st.session_state.get("csv_b_path", ""))
    sig_b_prev = st.session_state.get("df_B_signature", "")
    df_b_changed = sig_b != sig_b_prev
    st.session_state["df_B_signature"] = sig_b

    return df_a, df_b, dataset_changed, df_b_changed


def _ensure_conversation_store() -> None:
    st.session_state.setdefault("conversation_log", [])
    st.session_state.setdefault("active_run_id", None)


df_A, df_B, dataset_changed, df_b_changed = _get_dataframes()
df_a_ready = isinstance(df_A, pd.DataFrame)
st.session_state.setdefault("log_has_content", False)

_ensure_conversation_store()

sql_history = get_history("lc_msgs:sql")
eda_history = get_history("lc_msgs:eda")
if dataset_changed or df_b_changed:
    eda_history.clear()

def _render_chat_history(title: str, history) -> None:
    st.markdown(f"#### {title}")
    messages = getattr(history, "messages", []) or []
    if not messages:
        st.info("ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    for msg in messages:
        role = getattr(msg, "type", "assistant")
        if role == "human":
            streamlit_role = "user"
        elif role == "ai":
            streamlit_role = "assistant"
        else:
            streamlit_role = role or "assistant"
        content = msg.content if isinstance(msg.content, str) else str(msg.content)
        with st.chat_message(streamlit_role):
            st.markdown(content)
def _append_user_message(run_id: str, content: str) -> None:
    st.session_state["conversation_log"].append(
        {"run_id": run_id, "role": "user", "content": content}
    )


def _append_assistant_message(run_id: str, content: str, mode: str) -> None:
    st.session_state["conversation_log"].append(
        {
            "run_id": run_id,
            "role": "assistant",
            "mode": mode,
            "content": content,
            "figures": [],
            "figures_attached": False,
        }
    )


def _attach_figures_to_run(run_id: str, figures: List[Dict[str, Any]]) -> None:
    if not run_id or not figures:
        return
    log = st.session_state.get("conversation_log", [])
    for entry in reversed(log):
        if entry.get("run_id") == run_id and entry.get("role") == "assistant":
            if entry.get("figures_attached"):
                return
            entry.setdefault("figures", [])
            entry["figures"].extend(figures)
            entry["figures_attached"] = True
            break


def _append_dataframe_preview_message(label: str, df: pd.DataFrame, key: str) -> None:
    if not isinstance(df, pd.DataFrame) or df.empty:
        return
    preview_df = df.head(10)
    if preview_df.empty:
        return
    dataset_name_key = "df_A_name" if key == "A" else "df_B_name"
    dataset_name = st.session_state.get(dataset_name_key, label)
    message = (
        f"**{label} Preview:** `{dataset_name}` (Shape: {df.shape})"
    )
    run_id = f"preview-{key}-{uuid4()}"
    _append_assistant_message(run_id, message, "Data Preview")
    _attach_figures_to_run(
        run_id,
        [
            {
                "kind": "dataframe",
                "title": f"{label} Preview",
                "data": preview_df,
            }
        ],
    )


if df_a_ready and dataset_changed:
    if not st.session_state.pop("skip_next_df_a_preview", False):
        _append_dataframe_preview_message("df_A", df_A, "A")
if isinstance(df_B, pd.DataFrame) and df_b_changed:
    if not st.session_state.pop("skip_next_df_b_preview", False):
        _append_dataframe_preview_message("df_B", df_B, "B")


def _render_conversation_log(show_header: bool = True) -> None:
    if show_header:
        st.markdown("#### ëŒ€í™” ê¸°ë¡")
    log = st.session_state.get("conversation_log", [])
    if not log:
        st.info("ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    for entry in log:
        role = entry.get("role", "assistant")
        streamlit_role = "assistant" if role == "assistant" else "user"
        with st.chat_message(streamlit_role):
            mode = entry.get("mode")
            if mode and role == "assistant":
                st.caption(mode)
            content = entry.get("content", "")
            if content:
                st.markdown(content)
            for fig in entry.get("figures", []):
                title = fig.get("title")
                if title:
                    st.markdown(f"**{title}**")
                kind = fig.get("kind")
                if kind == "bar_chart":
                    st.bar_chart(fig.get("data"), use_container_width=True)
                elif kind == "line_chart":
                    st.line_chart(fig.get("data"), use_container_width=True)
                elif kind == "dataframe":
                    st.dataframe(fig.get("data"), use_container_width=True)
                elif kind == "json":
                    st.json(fig.get("data"))
                elif kind == "matplotlib":
                    image_b64 = fig.get("image")
                    if image_b64:
                        st.image(base64.b64decode(image_b64), use_column_width=True)


llm = load_llm()

pytool_obj = None
eda_agent_with_history = None
if df_a_ready:
    pytool_obj, eda_tools = build_tools(df_A, df_B)
    eda_prompt = build_react_prompt(df_A, df_B, eda_tools)
    _eda_agent, eda_agent_with_history = build_agent(
        llm,
        eda_tools,
        eda_prompt,
        lambda session_id: eda_history,
    )

sql_tools = build_sql_tools()
sql_prompt = build_sql_prompt(
    sql_tools,
    selected_table=st.session_state.get("databricks_selected_table", ""),
    selected_catalog=st.session_state.get("databricks_selected_catalog", ""),
    selected_schema=st.session_state.get("databricks_selected_schema", ""),
)
_sql_agent, sql_agent_with_history = build_agent(
    llm,
    sql_tools,
    sql_prompt,
    lambda session_id: sql_history,
)


BASE_CHAT_PLACEHOLDER = (
    "SQL) ì˜ˆ: sales_transactionsì—ì„œ ìµœê·¼ 7ì¼ê°„ ë§¤ì¶œ í•©ê³„ë¥¼ ìœ„í•œ SQL ì‘ì„±í•´ì¤˜ / "
    "EDA) ì˜ˆ: auto_outlier_eda() / plot_outliers('temperature') / compare_on_keys('machineID,datetime')"
)


def _infer_agent(user_message: str) -> str:
    text = (user_message or "").lower()
    last_mode = st.session_state.get("last_agent_mode", "SQL Builder")

    eda_keywords = [
        "eda",
        "ì´ìƒì ",
        "ì‹œê°í™”",
        "plot",
        "distribution",
        "auto_outlier",
        "anomaly",
        "stl",
        "cohort",
        "compare_on_keys",
        "rolling_stats",
        "mismatch_report",
        "describe_",
        "heatmap",
    ]
    sql_keywords = [
        "sql",
        "ì¿¼ë¦¬",
        "select",
        " from ",
        "join",
        "where",
        "catalog",
        "schema",
        "table",
        "run",
        "execute",
        "ì‹¤í–‰",
        "ìˆ˜í–‰",
        "databricks",
        "ì¡°íšŒ",
        "load",
    ]

    if any(keyword in text for keyword in eda_keywords):
        return "EDA Analyst"
    if any(keyword in text for keyword in sql_keywords):
        return "SQL Builder"
    if not df_a_ready:
        return "SQL Builder"
    return "EDA Analyst"


def _infer_table_from_sql(sql: str) -> str:
    text = (sql or "").strip()
    if not text:
        return ""
    lowered = text.lower()
    marker = " from "
    idx = lowered.find(marker)
    if idx == -1:
        if lowered.startswith("from "):
            idx = 0
        else:
            return ""
    idx += len(marker)
    remainder = text[idx:].strip()
    if not remainder:
        return ""
    candidate = remainder.split()[0]
    candidate = candidate.rstrip(";,)")
    return candidate.strip()


def _ensure_limit_clause(sql: str, limit: int = 2000) -> str:
    text = (sql or "").strip()
    if not text:
        return sql

    semicolon = "" if not text.endswith(";") else ";"
    body = text[:-1].rstrip() if semicolon else text

    pattern = re.compile(r"(?is)\blimit\s+\d+(\s+offset\s+\d+)?\s*$")
    match = pattern.search(body)
    if match:
        prefix = body[: match.start()].rstrip()
        offset_part = (match.group(1) or "").upper()
        body = f"{prefix} LIMIT {limit}{offset_part}"
    else:
        body = f"{body.rstrip()} LIMIT {limit}"

    return f"{body}{semicolon}"


with st.sidebar:
    st.markdown("#### ì›ë³¸ LangChain íˆìŠ¤í† ë¦¬")
    with st.expander("SQL Builder History", expanded=False):
        _render_chat_history("SQL Builder History", sql_history)
    with st.expander("EDA Analyst History", expanded=False):
        _render_chat_history("EDA Analyst History", eda_history)

    st.markdown("#### âš™ï¸ ì‹¤ì‹œê°„ ì‹¤í–‰ ë¡œê·¸")
    log_placeholder = st.container()
    if not st.session_state.get("log_has_content"):
        with log_placeholder.container():
            st.info("ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œ ì´ ì˜ì—­ì—ì„œ ë¡œê·¸ê°€ í‘œì‹œë©ë‹ˆë‹¤.")


def _execute_sql_preview(
    run_id: str,
    sql_text: str,
    *,
    log_container,
    auto_trigger: bool = False,
) -> bool:
    sql_to_run = (sql_text or "").strip()
    if not sql_to_run:
        warning_msg = "ì‹¤í–‰í•  SQLì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € SQL Builderë¡œ ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
        st.warning(warning_msg)
        _append_assistant_message(run_id, warning_msg, "SQL Execution")
        st.session_state["active_run_id"] = None
        return False

    st.session_state["last_sql_statement"] = sql_to_run
    st.session_state["last_agent_mode"] = "SQL Builder"
    st.session_state["log_has_content"] = True
    log_container.empty()
    with log_container.container():
        st.subheader("ì‹¤ì‹œê°„ ì‹¤í–‰ ë¡œê·¸")
        status_msg = (
            "SQL Builderê°€ ìƒì„±í•œ ì¿¼ë¦¬ë¥¼ Databricksì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤."
            if auto_trigger
            else "SQL Builderì˜ ë§ˆì§€ë§‰ ì¿¼ë¦¬ë¥¼ Databricksì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤."
        )
        st.write(status_msg)

    cfg = st.session_state.get("databricks_config", {})
    catalog = cfg.get("catalog") or "hive_metastore"
    schema = cfg.get("schema") or "default"
    cfg["catalog"] = catalog
    cfg["schema"] = schema
    st.session_state["databricks_config"] = cfg
    st.session_state.setdefault("databricks_selected_catalog", catalog)
    st.session_state.setdefault("databricks_selected_schema", schema)

    table_name_input = st.session_state.get("databricks_table_input", "").strip()
    selected_table = st.session_state.get("databricks_selected_table", "").strip()
    table_name_inferred = _infer_table_from_sql(sql_to_run)
    table_name = (
        table_name_input
        or selected_table
        or table_name_inferred
        or st.session_state.get("last_sql_table", "")
    )
    if not table_name:
        warning_msg = (
            "ì‹¤í–‰í•  í…Œì´ë¸”ì„ ê²°ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. SQL Builderì—ì„œ ì‚¬ìš©í•  í…Œì´ë¸”ì„ ì§€ì •í•˜ê±°ë‚˜ Sidebarì—ì„œ í…Œì´ë¸”ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
        )
        st.warning(warning_msg)
        _append_assistant_message(run_id, warning_msg, "SQL Execution")
        st.session_state["active_run_id"] = None
        return False

    answer_container = st.container()
    with st.spinner("Databricks SQL ì‹¤í–‰ ì¤‘..."):
        success, message = load_preview_from_databricks_query(
            table_name,
            query=sql_to_run,
            target="A",
            limit=10,
        )
    preview_payloads: List[Dict[str, Any]] = []
    with answer_container:
        st.subheader("Answer")
        if success:
            st.success(message)
        else:
            st.error(message)

    if success:
        st.session_state["last_agent_mode"] = "EDA Analyst"
        st.session_state["last_sql_table"] = table_name
        st.session_state["databricks_table_input"] = table_name
        st.session_state["databricks_selected_table"] = table_name
        st.session_state["skip_next_df_a_preview"] = True
        df_latest = st.session_state.get("df_A_data")
        if isinstance(df_latest, pd.DataFrame) and not df_latest.empty:
            preview_payloads.append(
                {
                    "kind": "dataframe",
                    "title": f"df_A Preview â€” {st.session_state.get('df_A_name', 'df_A')}",
                    "data": df_latest.head(10),
                }
            )

    mode_label = "SQL Execution" if auto_trigger else "SQL Builder"
    _append_assistant_message(run_id, message, mode_label)
    if preview_payloads:
        _attach_figures_to_run(run_id, preview_payloads)
    st.session_state["active_run_id"] = None
    if success:
        rerun_callable = getattr(st, "rerun", None) or getattr(st, "experimental_rerun", None)
        if callable(rerun_callable):
            rerun_callable()
    return success

st.write("---")

_render_conversation_log()

if df_a_ready:
    with st.popover("ğŸ“Š Data Preview"):
        st.write(
            f"**Loaded file for df_A:** `{st.session_state['df_A_name']}` (Shape: {df_A.shape})"
        )
        st.dataframe(df_A.head(10), width="stretch")
        if isinstance(df_B, pd.DataFrame):
            st.markdown(
                f"**df_B Preview â€”** `{st.session_state['df_B_name']}` (Shape: {df_B.shape})"
            )
            st.dataframe(df_B.head(10), width="stretch")
else:
    st.info(
        "df_A ë°ì´í„°ê°€ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì™¼ìª½ Databricks Loader ë˜ëŠ” SQL Builder ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì„¸ìš”."
    )

chat_placeholder = BASE_CHAT_PLACEHOLDER

chat_input_key = "main_chat_input"
if chat_input_key not in st.session_state:
    st.session_state[chat_input_key] = ""

prefill_value = st.session_state.get("chat_input_prefill", "")
if prefill_value:
    st.session_state[chat_input_key] = prefill_value
    st.session_state["chat_input_prefill"] = ""

user_q = st.chat_input(chat_placeholder, key=chat_input_key)

if user_q:
    run_id = str(uuid4())
    st.session_state["active_run_id"] = run_id
    original_user_q = user_q
    _append_user_message(run_id, original_user_q)

    stripped_for_command = original_user_q.lstrip()
    lowered_for_command = stripped_for_command.lower()
    command_prefix = None
    agent_request = original_user_q

    if lowered_for_command.startswith("%sql"):
        command_prefix = "sql"
        agent_request = stripped_for_command[4:].lstrip()
    elif lowered_for_command.startswith("%eda"):
        command_prefix = "eda"
        agent_request = stripped_for_command[4:].lstrip()

    if command_prefix == "eda":
        st.session_state["chat_input_prefill"] = "%eda "
    else:
        st.session_state["chat_input_prefill"] = ""

    normalized_original = original_user_q.strip().lower()
    if command_prefix is None and normalized_original in {"ì‹¤í–‰", "ìˆ˜í–‰", "run", "execute"}:
        _execute_sql_preview(
            run_id,
            st.session_state.get("last_sql_statement", ""),
            log_container=log_placeholder,
        )
        st.stop()

    auto_execute_sql = command_prefix == "sql"

    if command_prefix == "sql":
        agent_mode = "SQL Builder"
    elif command_prefix == "eda":
        agent_mode = "EDA Analyst"
    else:
        agent_mode = _infer_agent(original_user_q)
    st.session_state["last_agent_mode"] = agent_mode

    if not agent_request:
        if command_prefix == "sql":
            agent_request = "ìƒˆë¡œìš´ SQL ì¿¼ë¦¬ë¥¼ ì‘ì„±í•´ì¤˜."
        elif command_prefix == "eda":
            agent_request = "ë¡œë“œëœ ë°ì´í„°í”„ë ˆì„ì— ëŒ€í•´ ê¸°ë³¸ EDAë¥¼ ìˆ˜í–‰í•´ì¤˜."
        else:
            agent_request = original_user_q

    if agent_mode == "EDA Analyst" and not df_a_ready:
        error_msg = (
            "df_A ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € SQL Builder ì—ì´ì „íŠ¸ë‚˜ Databricks Loaderë¡œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¨ ë’¤ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
        )
        st.error(error_msg)
        _append_assistant_message(run_id, error_msg, agent_mode)
        st.session_state["active_run_id"] = None
    else:
        st.session_state["log_has_content"] = True
        log_placeholder.empty()
        with log_placeholder.container():
            st.subheader("ì‹¤ì‹œê°„ ì‹¤í–‰ ë¡œê·¸")
            log_stream_container = st.container()
        st_cb = StreamlitCallbackHandler(log_stream_container)
        collector = SimpleCollectCallback()
        answer_container = st.container()

        agent_runner = (
            sql_agent_with_history if agent_mode == "SQL Builder" else eda_agent_with_history
        )
        session_id = (
            "databricks_sql_builder"
            if agent_mode == "SQL Builder"
            else "two_csv_compare_and_ssd_eda"
        )
        spinner_text = (
            "Databricks SQLì„ êµ¬ìƒ ì¤‘ì…ë‹ˆë‹¤..."
            if agent_mode == "SQL Builder"
            else "Thinking with Gemini..."
        )

        with st.spinner(spinner_text):
            try:
                result = agent_runner.invoke(
                    {"input": agent_request},
                    {
                        "callbacks": [st_cb, collector, StdOutCallbackHandler()],
                        "configurable": {"session_id": session_id},
                    },
                )
            except Exception as exc:
                error_text = str(exc)
                lower_error = error_text.lower()
                if "serviceunavailable" in lower_error or "model is overloaded" in lower_error:
                    friendly = (
                        "Gemini ëª¨ë¸ì´ ì¼ì‹œì ìœ¼ë¡œ ê³¼ë¶€í•˜ ìƒíƒœì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                    )
                    st.warning(friendly)
                    st.info("í•„ìš”ì‹œ ê°™ì€ ìš”ì²­ì„ ì¡°ê¸ˆ ë’¤ì— ë‹¤ì‹œ ë³´ë‚´ì£¼ì„¸ìš”.")
                    result = {"output": friendly}
                else:
                    st.error(f"Agent ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {error_text}")
                    result = {"output": f"Agent ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {error_text}"}

        st.success("Done.")
        final = result.get(
            "output", "Agentê°€ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        )
        with answer_container:
            st.subheader("Answer")
            final_text = final if isinstance(final, str) else str(final)
            sql_capture = ""
            if agent_mode == "SQL Builder" and "SQL:" in final_text:
                tail = final_text.split("SQL:", 1)[1]
                if "Explanation:" in tail:
                    sql_capture = tail.split("Explanation:", 1)[0].strip()
                elif "Execution:" in tail:
                    sql_capture = tail.split("Execution:", 1)[0].strip()
                else:
                    sql_capture = tail.strip()
                if sql_capture:
                    enforced_sql = _ensure_limit_clause(sql_capture)
                    if enforced_sql != sql_capture:
                        final_text = final_text.replace(sql_capture, enforced_sql, 1)
                    sql_capture = enforced_sql

            final_display = final_text
            if final_text.strip():
                try:
                    translation_prompt = (
                        "ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•œ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì¤˜.\n\n"
                        f"{final_text}"
                    )
                    translated_msg = llm.invoke(translation_prompt)
                    translated_text = getattr(translated_msg, "content", None)
                    if translated_text:
                        final_display = translated_text
                except Exception as exc:
                    st.warning(f"í•œêµ­ì–´ ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
            st.caption(f"{agent_mode} ì‘ë‹µ")
            st.write(final_display)
            _append_assistant_message(run_id, final_display, agent_mode)

            if agent_mode == "SQL Builder" and sql_capture:
                st.session_state["last_sql_statement"] = sql_capture
                st.session_state["last_sql_label"] = original_user_q.strip()[:80] or "SQL Query"
                table_hint = (
                    st.session_state.get("databricks_table_input", "").strip()
                    or st.session_state.get("databricks_selected_table", "").strip()
                    or _infer_table_from_sql(sql_capture)
                    or st.session_state.get("last_sql_table", "")
                )
                if table_hint:
                    st.session_state["last_sql_table"] = table_hint
                    st.session_state["databricks_selected_table"] = table_hint
                if auto_execute_sql:
                    _execute_sql_preview(
                        run_id,
                        sql_capture,
                        log_container=log_placeholder,
                        auto_trigger=True,
                    )

            if agent_mode == "EDA Analyst" and pytool_obj is not None:
                figure_payloads = render_visualizations(pytool_obj)
                _attach_figures_to_run(run_id, figure_payloads)
        st.session_state["active_run_id"] = None
